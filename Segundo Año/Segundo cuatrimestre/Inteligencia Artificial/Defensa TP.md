-- -
# 1. ¬øQu√© es el **aprendizaje supervisado**?

Es un tipo de entrenamiento de modelos donde el algoritmo aprende **a partir de datos etiquetados**.  
Esto significa que **cada entrada (input)** en el conjunto de datos **tiene una salida (output) conocida**, es decir, una ‚Äúrespuesta correcta‚Äù.

### Ejemplo:

Si quer√©s entrenar un modelo para detectar fraudes:

- Input: caracter√≠sticas de una transacci√≥n (monto, hora, ubicaci√≥n, etc.)
    
- Output: etiqueta que indica si fue **fraude (1)** o **no fraude (0)**
    

El modelo **aprende a predecir** esa salida a partir de los ejemplos anteriores.

### Objetivo:

Aprender una **funci√≥n que relacione entradas con salidas** para poder predecir nuevas instancias correctamente.

---

## ¬øQu√© es el **aprendizaje no supervisado**?

En este caso, el modelo **no recibe etiquetas**. Solo se le dan los datos sin decirle cu√°l es la salida correcta.

### Ejemplo:

Un dataset con miles de transacciones, pero **sin saber cu√°les son fraudulentas** y cu√°les no.

### Objetivo:

Descubrir **patrones ocultos o agrupamientos (clusters)** en los datos.

---

## Diferencias clave

|Caracter√≠stica|Aprendizaje Supervisado|Aprendizaje No Supervisado|
|---|---|---|
|**Etiquetas (output conocido)**|‚úÖ S√≠|‚ùå No|
|**Ejemplos t√≠picos**|Clasificaci√≥n, regresi√≥n|Clustering, reducci√≥n de dimensionalidad|
|**Ejemplo pr√°ctico**|Detectar fraudes, reconocer spam|Agrupar clientes seg√∫n su comportamiento|
|**Entrada de datos**|Input + Output|Solo Input|
|**Resultado esperado**|Modelo que predice salidas conocidas|Estructura interna de los datos|

---

## En tu TP:

Usaste **aprendizaje supervisado** porque el modelo fue entrenado con **transacciones ya etiquetadas como fraude o no fraude**, y se busc√≥ que **aprendiera a clasificar nuevas transacciones** correctamente.

-- -

# 2. ¬øQu√© es una Red Neuronal Profunda?

Las **Redes Neuronales Profundas (DNN, por _Deep Neural Networks_)** son una clase de modelos de aprendizaje supervisado inspirados en el funcionamiento del cerebro humano. Son una extensi√≥n de las redes neuronales artificiales tradicionales, pero con **m√°s capas ocultas**, lo que les permite aprender representaciones complejas y abstractas de los datos.

---

Una DNN es una red neuronal que tiene:

- Una **capa de entrada** (input layer)
    
- **Varias capas ocultas** (hidden layers) ‚Äî esto es lo que la hace ‚Äúprofunda‚Äù
    
- Una **capa de salida** (output layer)
    

Cuantas m√°s **capas ocultas** tenga la red, **m√°s profunda** es.

---

### Estructura b√°sica de una DNN

```
Entrada ‚Üí Capa oculta 1 ‚Üí Capa oculta 2 ‚Üí ... ‚Üí Capa oculta N ‚Üí Salida
```

Cada capa est√° compuesta por **neuronas artificiales**, que aplican una funci√≥n matem√°tica sobre los datos y las **pesan** en base al entrenamiento.

---

## ¬øQu√© hacen las DNN?

Las redes neuronales profundas **aprenden representaciones jer√°rquicas de los datos**. Por ejemplo, en im√°genes:

- Las primeras capas pueden detectar bordes
    
- Las intermedias pueden detectar formas
    
- Las √∫ltimas pueden detectar objetos complejos
    

En tu caso, aplicado a **detecci√≥n de fraudes**:

- Capas iniciales pueden identificar patrones simples (como montos altos)
    
- Capas intermedias pueden identificar combinaciones sospechosas (ubicaci√≥n + hora)
    
- Capas finales deciden si es fraude o no
    

---

## ¬øPor qu√© son poderosas?

Las DNN:

- Aprenden **caracter√≠sticas autom√°ticamente** (no necesitan que se las definan manualmente)
    
- Pueden capturar **relaciones no lineales muy complejas**
    
- Funcionan muy bien con **grandes vol√∫menes de datos**
    

---

## Elementos clave en una DNN

|Componente|Descripci√≥n|
|---|---|
|**Neuronas**|Cada una realiza un c√°lculo: suma ponderada + funci√≥n de activaci√≥n|
|**Pesos (weights)**|Valores que indican la importancia de cada entrada|
|**Funciones de activaci√≥n**|Como ReLU, Sigmoid, Tanh. Introducen no linealidad|
|**Backpropagation**|Algoritmo que ajusta los pesos durante el entrenamiento|
|**Funci√≥n de p√©rdida (loss)**|Mide qu√© tan mal predice la red, para corregir errores|
|**Optimizaci√≥n (e.g., Adam)**|Algoritmo que busca minimizar la funci√≥n de p√©rdida|

---

## En tu TP

Usaron una red neuronal profunda con capas como:

- **Input Layer:** recibe los features de la transacci√≥n
    
- **Hidden Layers:** extraen combinaciones complejas de patrones
    
- **Output Layer:** devuelve 1 (fraude) o 0 (no fraude)
    

Y aplicaron:

- **Funciones de activaci√≥n ReLU y Sigmoid**
    
- **Backpropagation**
    
- **Funci√≥n de p√©rdida Binary Cross Entropy**
    
- **Optimizador Adam**
    

---

# 3. Funciones de Activaci√≥n: **ReLU** y **Sigmoid**

Las **funciones de activaci√≥n** son funciones matem√°ticas que se aplican a la salida de cada neurona. Le permiten a la red **modelar relaciones no lineales**, lo cual es esencial para problemas complejos como la detecci√≥n de fraudes.

### ReLU (_Rectified Linear Unit_)

**F√≥rmula:**  
$$  
f(x) = \max(0, x)  
$$

**Qu√© hace:**

- Devuelve el mismo valor si es positivo
    
- Devuelve 0 si es negativo
    

**Ventajas:**

- Simple y eficiente computacionalmente
    
- Ayuda a evitar el problema del **desvanecimiento del gradiente**
    
- Funciona muy bien en capas ocultas
    

**En tu TP:**  
Usaron **ReLU en las capas ocultas** para extraer patrones no lineales complejos de los datos.

---

### Sigmoid

**F√≥rmula:**  
$$  
f(x) = \frac{1}{1 + e^{-x}}  
$$

**Qu√© hace:**

- Comprime la salida entre 0 y 1
    
- Interpretable como una **probabilidad**
    

**En tu TP:**  
Usaron **Sigmoid en la capa de salida**, ya que el objetivo es **clasificar**:

- 0 = transacci√≥n normal
    
- 1 = transacci√≥n fraudulenta
    

---

## 2. Backpropagation

Es el **algoritmo de entrenamiento** que permite a la red aprender.

### ¬øQu√© hace?

Ajusta los **pesos de las conexiones** entre neuronas, **minimizando el error** en la predicci√≥n.

### ¬øC√≥mo funciona?

1. **Forward pass:** se calcula la salida de la red con los pesos actuales
    
2. **Se mide el error** entre la salida obtenida y la salida esperada (ground truth)
    
3. **Se propaga el error hacia atr√°s** desde la salida hasta la entrada
    
4. Se calcula el **gradiente de la funci√≥n de p√©rdida** con respecto a cada peso
    
5. Se **actualizan los pesos** para minimizar ese error
    

### ¬øCon qu√© se combina?

Con un **optimizador**, como **Adam**, que decide cu√°nto y c√≥mo ajustar los pesos.

---

## üìâ 3. Funci√≥n de P√©rdida: **Binary Cross Entropy**

Es una funci√≥n que mide qu√© tan mal est√°n las predicciones de la red respecto a los valores reales.  
Se usa en **clasificaci√≥n binaria** (como fraude vs no fraude).

### F√≥rmula:

$$  
\text{Loss} = -[y \cdot \log(\hat{y}) + (1 - y) \cdot \log(1 - \hat{y})]  
$$

Donde:

- $y$: valor real (0 o 1)
    
- $\hat{y}$: probabilidad predicha por la red
    

### ¬øPor qu√© se usa?

- Penaliza mucho cuando la red est√° muy equivocada
    
- Da resultados en escala de 0 a 1, ideal para tareas de clasificaci√≥n
    

**En tu TP:**  
La red fue entrenada para minimizar este error entre las predicciones y la realidad.

---

## 4. Optimizador **Adam**

Es un **algoritmo de optimizaci√≥n** muy usado para entrenar redes neuronales.

### ¬øQu√© hace?

Durante el backpropagation, decide **cu√°nto deben ajustarse los pesos** para reducir la p√©rdida.

### ¬øPor qu√© es tan usado?

- Combina lo mejor de dos algoritmos: **Momentum** y **RMSProp**
    
- Ajusta autom√°ticamente la tasa de aprendizaje para cada peso
    
- Es eficiente y robusto, ideal para datasets grandes y ruidosos
    

**En tu TP:**  
Se us√≥ **Adam** para optimizar los pesos y garantizar que la red converja m√°s r√°pido.

---

## En resumen, en tu TP:

|Componente|Rol|
|---|---|
|**ReLU**|Funci√≥n de activaci√≥n en capas ocultas|
|**Sigmoid**|Activaci√≥n final para devolver una probabilidad de fraude|
|**Binary Cross Entropy**|Mide el error de predicci√≥n en clasificaci√≥n binaria|
|**Backpropagation**|Propaga el error y ajusta los pesos|
|**Adam**|Decide c√≥mo ajustar los pesos para minimizar el error|

---

# Explicacion diagramas

## Explicaci√≥n del Diagrama de Flujo del Sistema DNN

![[Pasted image 20251021153833.png]]


El diagrama ilustra el _pipeline_ (flujo de trabajo) de preparaci√≥n de datos para el **Sistema de Detecci√≥n de Fraude (DNN)**, desde que se reciben las transacciones hasta que est√°n listas para el entrenamiento del modelo de Inteligencia Artificial.

|**Paso**|**Bloque del Diagrama**|**Significado y Prop√≥sito**|
|---|---|---|
|**Inicio**|**Transacciones Brutas**|Es la materia prima: el conjunto de registros hist√≥ricos de transacciones financieras tal como se reciben. Estos datos incluyen variables con diferentes escalas (ej: montos grandes y horas peque√±as), valores categ√≥ricos (ej: tipo de tarjeta) y el desequilibrio natural de clases (mucho "No Fraude", poco "Fraude").|
|**1**|**Preprocesamiento y Escalamiento**|Se aplica la limpieza de datos (eliminar valores nulos o inconsistencias) y el **Escalamiento** (usando _StandardScaler_). Este paso es crucial para que todas las variables num√©ricas tengan la misma magnitud. Esto es vital para que el algoritmo de optimizaci√≥n (Descenso de Gradiente, como Adam) funcione de manera eficiente y justa, sin que una caracter√≠stica domine a las dem√°s solo por tener un valor num√©rico grande.|
|**2**|**Datos Escalados (D1)**|Es el resultado del primer paso: las transacciones est√°n ahora listas para el modelo (limpias, con variables categ√≥ricas codificadas y con magnitudes uniformes).|
|**3**|**Divisi√≥n Train/Test**|Los datos escalados se dividen en dos subconjuntos principales: **Entrenamiento (Train)** y **Prueba (Test)**. Esta divisi√≥n debe hacerse con la estrategia _stratify_ (estratificada) para asegurar que el conjunto de entrenamiento y el de prueba tengan una proporci√≥n similar de casos de fraude/no fraude.|
|**4**|**Conclusi√≥n**|Representa la fase final del proceso de modelado, donde la arquitectura DNN (Red Neuronal Profunda) entrenar√° con los datos de **Entrenamiento** y ser√° evaluada con los datos de **Prueba** para determinar su rendimiento (usando m√©tricas como Loss, Accuracy y **Recall**).|
